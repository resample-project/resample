{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bootstrap and Jackknife comparison\n",
    "\n",
    "In this notebook we compare the bootstrap to the jackknife. Bootstrap resampling is superior to jackknifing, but the jackknife is deterministic, which may be helpful, and it can exactly remove biases of order 1/N from an estimator (the bootstrap removes biases of higher orders, too, but it does not remove the lowest order exactly)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from resample.jackknife import variance as j_var, resample as j_resample, bias as j_bias\n",
    "from resample.bootstrap import resample as b_resample\n",
    "import numpy as np\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "theta                [0.037 0.333]\n",
      "std.dev. (jackknife) [0.132 0.098]\n",
      "std.dev. (bootstrap) [0.126 0.089]\n",
      "bias (jackknife)     [-0.    -0.018]\n",
      "bias (bootstrap)     [ 0.    -0.016]\n",
      "bias (exact)         [ 0.    -0.018]\n"
     ]
    }
   ],
   "source": [
    "rng = np.random.default_rng(1)\n",
    "data = rng.normal(size=20)\n",
    "\n",
    "\n",
    "# get mean and std deviation\n",
    "def fn(d):\n",
    "    return np.mean(d), np.var(d, ddof=0) # we return the biased variance\n",
    "\n",
    "\n",
    "# compute bias with the bootstrap\n",
    "def b_bias(fn, sample):\n",
    "    theta = fn(sample)\n",
    "    b_rep = [fn(s) for s in b_resample(sample, random_state=rng)]\n",
    "    return np.mean(b_rep, axis=0) - theta\n",
    "\n",
    "\n",
    "# compute variance with bootstrap\n",
    "def b_var(fn, sample):\n",
    "    b_rep = [fn(s) for s in b_resample(sample, random_state=rng)]\n",
    "    return np.var(b_rep, axis=0)\n",
    "\n",
    "# exact bias for biased standard deviation\n",
    "# - we computed: s = 1/N * sum(x ** 2 - np.mean(x) ** 2)\n",
    "# - correct is:  N/(N-1) * s\n",
    "# - bias is: (1 - N/(N-1)) * s = (N - 1 - N) / (N - 1) * s = - 1 / (N - 1) * s\n",
    "\n",
    "\n",
    "print(\"theta               \", np.round(fn(data), 3))\n",
    "print(\"std.dev. (jackknife)\", np.round(j_var(fn, data) ** 0.5, 3))\n",
    "print(\"std.dev. (bootstrap)\", np.round(b_var(fn, data) ** 0.5, 3))\n",
    "print(\"bias (jackknife)    \", np.round(j_bias(fn, data), 3))\n",
    "print(\"bias (bootstrap)    \", np.round(b_bias(fn, data), 3))\n",
    "print(\"bias (exact)        \", np.round((0, -1 / (len(data) - 1) * fn(data)[1]), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The standard deviations for the estimates computed by bootstrap and jackknife differ by about 10 %. This difference shrinks for larger data sets.\n",
    "\n",
    "Both resampling methods find no bias for the mean, and a small bias for the (not bias-corrected) variance. The jackknife is getting closer, since the bias for sufficiently large N is dominated by the O(1/N) order that the jackknife removes exactly."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
